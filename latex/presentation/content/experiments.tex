\section{Experiments}
\begin{frame}{Experiments and Results}
\framesubtitle{Baselines}
We compare our proposed method to multiple baseline methods, including
\begin{itemize}
\item Shallow approaches:
\begin{itemize}
\item Logistic Regression
\item Na\"ive Bayes
\item SVM
\end{itemize}
\item Deep approaches:
\begin{itemize}
\item BiGRU Sequence-to-Sequence
\item CNN and Multi-channel CNN with LSTM / BiGRU
\item Finetuned LLMs: BERT and XLM-RoBERTa.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Experiments (cont.)}
\framesubtitle{Datasets}

We conduct experiments on two datasets: TREC (multiclass) and SST2 (binary class).

\begin{table}
\centering
\begin{tabular}{|c|c|c|}\hline%c|c|c|} \hline
\textbf{Training} & \textbf{Testing} & \textbf{Coarse labels} \\ \hline%& \textbf{Fine class labels} & \textbf{Avg. length} & \textbf{Vocab. size} \\ \hline
5500              & 500              & 6                    \\ \hline %  & 50                         & 10                   & 8700                 \\ \hline
\end{tabular}
\caption{Statistics of the TREC dataset\cite{hovy2001, li2002}} \label{tab:trec-insight}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|} \hline
\textbf{Training} & \textbf{Validation} & \textbf{Testing} & \textbf{Labels} \\ \hline
47144              & 20205              & 872                      & 2 \\ \hline
\end{tabular}
\caption{Statistics of the SST2 dataset\cite{Socher2013}} \label{tab:sst2-insight}
\end{table}
\end{frame}

\begin{frame}{Experiments (cont.)}
\framesubtitle{Metrics}

We use Accuracy, Precision, Recall and F1 score as evaluation metrics.
\begin{equation}
Accuracy  = \displaystyle\frac{1}{n}\sum_{i = 1}^n (y_i = \hat{y_i})
\end{equation}

With $TP, FP$ and $FN$ are True Positive, False Positive and False Negative samples, respectively:

\begin{equation}
\begin{aligned}
Precision\ (P) &= \frac{TP}{TP + FP} \\
Recall\ (R) &= \frac{TP}{TP + FN} \\
F_{1} &= \frac{2PR}{P + R}    
\end{aligned}
\end{equation}
\end{frame}

% \begin{frame}{Experiments (cont.)}
% \framesubtitle{Setup -- Shallow models}
% TBD
% \end{frame}


% \begin{frame}{Experiments (cont.)}
% \framesubtitle{Setup -- Deep models}
% TBD
% \end{frame}

% \begin{frame}{Experiments (cont.)}
% \framesubtitle{Setup -- Deep models}
% TBD
% \end{frame}

\begin{frame}{Results}
\framesubtitle{Performance Analysis -- TREC dataset}

\begin{table}
\small{
\begin{tabular*}{\linewidth}{@{\extracolsep\fill}lcccc}
\hline
\textbf{Model}                & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} &  \textbf{F1} \\ \hline
Logistic Regression   & 0.852 & 0.831          & 0.897       & 0.856  \\ 
Multinomial Naive Bayes   & 0.832 & 0.704          & 0.699       & 0.697 \\ 
Support Vector Classifier & 0.886 & 0.862          & 0.912       & 0.882  \\ \hline
BiGRU Seq2Seq            & 0.836 & 0.695          & 0.708       & 0.700  \\ \hline
CNN + random embedding                 & 0.726 & 0.809          & 0.684       & 0.718   \\
CNN + fastText (freeze)   & 0.924 & 0.933          & 0.898       & 0.912    \\
CNN + fastText (trainable) & 0.910 & 0.922          & 0.885       & 0.899    \\ \hline
CNN + LSTM + random embedding  & 0.652 & 0.717          & 0.637       & 0.631  \\
CNN + BiGRU + random embedding     & 0.676 & 0.717          & 0.701       & 0.689   \\
CNN + BiGRU + fastText (freeze)   & 0.914 & 0.919          & 0.896       & 0.904  \\
CNN + BiGRU + fastText (trainable) & 0.902 & 0.892          & 0.884       & 0.886 \\ \hline
Finetuned BERT & \textbf{0.976} & \textbf{0.978} & \textbf{0.982} & \textbf{0.979}  \\
Finetuned XLM-RoBERTa & 0.966 & 0.971          & 0.970       & 0.970  \\ \hline
Finetuned DistilBERT  & 0.974 & 0.976 & 0.977  & 0.976  \\ \hline
\end{tabular*}
}
\caption{Experiment metrics on the TREC dataset. Bold indicates the highest scores.} \label{tab:result-TREC}
\end{table}
\end{frame}

\begin{frame}{Results (cont.)}
\framesubtitle{Performance Analysis -- SST2 dataset}
\begin{table}
\small{
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lcccc}
\hline
\textbf{Model}                & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} &  \textbf{F1} \\ \hline
Logistic Regression   & 0.807 & 0.806 & 0.810 & 0.807 \\ 
Multinomial Naive Bayes   & 0.808 & 0.807 & 0.819 & 0.806 \\ 
Support Vector Classifier & 0.829 & 0.829 & 0.830 & 0.829  \\ \hline
BiGRU Seq2Seq  & 0.765 & 0.766 & 0.764 & 0.764 \\ \hline
CNN + random embedding  & 0.760 & 0.774 & 0.758 & 0.756   \\
CNN + fastText (freeze)   & 0.830 & 0.834 & 0.829 & 0.830 \\
CNN + fastText (trainable) & 0.843 & 0.851 & 0.842 & 0.842 \\ \hline

CNN + LSTM + random embedding  & 0.734 & 0.741 & 0.735 & 0.733  \\
CNN + BiGRU + random embedding     & 0.748 & 0.754 & 0.749 & 0.747   \\
CNN + BiGRU + fastText (freeze)   & 0.815 & 0.818 & 0.816 & 0.815  \\
CNN + BiGRU + fastText (trainable) & 0.806 & 0.813 & 0.805 & 0.805 \\ \hline 
Finetuned BERT & 0.906 & 0.905 & 0.909 & 0.906  \\
Finetuned XLM-RoBERTa & \textbf{0.911} & \textbf{0.911} & \textbf{0.911} & \textbf{0.911}  \\ \hline
Finetuned DistilBERT  & 0.905 & 0.904 & 0.906 & 0.905  \\ \hline
\end{tabular*}
}
\caption{Experiment metrics on the SST2 dataset. Bold indicates the highest scores.} \label{tab:result-SST2}
\end{table}
\end{frame}

\begin{frame}{Results (cont.)}
\framesubtitle{Inference Time Analysis}

\begin{table}
\small{
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccc}
\toprule
 & \multicolumn{2}{@{}c@{}}{\textbf{Inference time}} \\ \cmidrule{2-3}%
\textbf{Model}  & \textbf{TREC}  & \textbf{SST2}\\ \toprule
BiGRU Seq2Seq                      & 1.812 $\pm$ 0.668 ms &  3.394 $\pm$ 1.222 ms                     \\ \midrule
CNN + random embedding             & 1.673 $\pm$ 0.359 ms & 2.378 $\pm$ 0.747 ms                  \\
CNN + fastText (freeze)           & 1.610 $\pm$ 0.318 ms & 1.705 $\pm$ 0.379 ms                     \\
CNN + fastText (trainable)         & 1.658 $\pm$ 0.444 ms & 1.780 $\pm$ 0.329 ms                    \\ \midrule
CNN + LSTM + random embedding      & 5.626 $\pm$ 0.750 ms & 6.607 $\pm$ 1.010 ms                   \\
CNN + BiGRU + random embedding     & 11.387 $\pm$ 3.077 ms & 10.419 $\pm$ 1.635 ms                   \\
CNN + BiGRU + fastText (freeze)   & 10.211 $\pm$ 1.460 ms & 11.769 $\pm$ 3.032 ms                  \\
CNN + BiGRU + fastText (trainable) & 10.270 $\pm$ 2.187 ms & 13.386 $\pm$ 3.206 ms                  \\ \midrule
Finetuned BERT                     & 17.725 $\pm$ 4.071 ms & 16.984 $\pm$ 4.228 ms                  \\
Finetuned XLM-RoBERTa              & 16.933 $\pm$ 8.987 ms & 15.848 $\pm$ 3.840 ms                  \\ \midrule
Finetuned DistilBERT               & 9.776 $\pm$ 2.499 ms & 9.629 $\pm$ 6.478 ms                    \\ \bottomrule
\end{tabular*}
}
\caption{Inference time of deep learning approaches on testing sets}\label{tab:inference-result}
\end{table}
\end{frame}

\begin{frame}{Results (cont.)}
\framesubtitle{Parameter Analysis}
\begin{table}
\small{
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccc}
\toprule
 & \multicolumn{2}{@{}c@{}}{\textbf{Total parameters}} \\ \cmidrule{2-3}%
\textbf{Model}  & \textbf{TREC}  & \textbf{SST2}\\ \midrule
BiGRU Seq2Seq                      & 18,461,702 &  20,254,722                     \\ \midrule
CNN + random embedding             & 3,192,606 & 4,802,702                  \\
CNN + fastText (freeze)           & 362,106 & 360,902                     \\
CNN + fastText (trainable)         & 3,192,606 & 4,802,702                    \\ \midrule
CNN + LSTM + random embedding      & 4,420,416 & 6,568,012                   \\
CNN + BiGRU + random embedding     & 4,504,896 & 6,652,492                   \\
CNN + BiGRU + fastText (freeze)   & 987,696 & 986,892                  \\
CNN + BiGRU + fastText (trainable) & 6,648,696 & 9,870,492                 \\ \midrule
Finetuned BERT                     & 108,314,886 & 108,311,810                  \\
Finetuned XLM-RoBERTa              & 278,048,262 & 278,045,186                  \\ \midrule
Finetuned DistilBERT  & 65,786,118 & 65,783,042                    \\ \bottomrule
\end{tabular*}
}
\caption{Total parameters of deep learning approaches}\label{tab:parameters-result}
\end{table}
\end{frame}